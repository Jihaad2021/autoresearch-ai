# AutoResearch AI - Complete Project Documentation

**Version**: 1.0  
**Last Updated**: November 25, 2024  
**Project Status**: Sprint 1 - 50% Complete

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#project-overview)
2. [Problem Statement](#problem-statement)
3. [Solution Architecture](#solution-architecture)
4. [Technical Stack](#technical-stack)
5. [System Components](#system-components)
6. [Data Models & Schemas](#data-models--schemas)
7. [Agent Specifications](#agent-specifications)
8. [Worker Specifications](#worker-specifications)
9. [Workflow & State Machine](#workflow--state-machine)
10. [Implementation Details](#implementation-details)
11. [Testing Strategy](#testing-strategy)
12. [Deployment Architecture](#deployment-architecture)
13. [Development Progress](#development-progress)

---

## ğŸ¯ Project Overview

### What is AutoResearch AI?

**AutoResearch AI** is an autonomous multi-agent system that researches topics, analyzes information, writes comprehensive content, and ensures quality through collaborative review - all with minimal human intervention.

### Key Concept

Instead of a single LLM doing everything (which leads to shallow research and hallucinations), we use **specialized AI agents working together** like a professional content team:
```
Research Team (parallel) â†’ Analysis Team â†’ Writing Team â†’ Quality Team
        â†“                       â†“              â†“              â†“
   Find sources          Extract insights  Create article  Verify quality
```

### Value Proposition

| Metric | Value |
|--------|-------|
| **Automation Level** | 85%+ (minimal human intervention) |
| **Content Quality** | 88/100 (human evaluation target) |
| **Research Depth** | 10-15 sources per article |
| **Time Savings** | 70% vs manual process (10 hours â†’ 25 minutes) |
| **Cost** | ~$2-3 per 2000-word article |
| **Scalability** | 500+ articles/day (vs 1-2 for human) |

### Target Users

1. **Content Marketing Agencies** - Need 50-100 articles/month
2. **Research Teams** - Stay updated on rapidly changing fields
3. **Technical Writers** - Document complex topics accurately
4. **Students & Academics** - Literature reviews and research summaries
5. **Companies** - Internal knowledge bases and documentation

---

## ğŸ¯ Problem Statement

### The Challenge

**Content creation is time-consuming and requires multiple specialized skills:**

#### Traditional Manual Process
```
1. Research phase (4-6 hours)
   - Search for sources
   - Read multiple articles
   - Take notes
   - Verify information

2. Writing phase (3-4 hours)
   - Structure outline
   - Write draft
   - Add citations

3. Editing phase (2-3 hours)
   - Review for accuracy
   - Check grammar
   - Verify citations
   - Optimize for SEO

Total: 9-13 hours per article
Required skills: Research, writing, editing, SEO
```

### Current AI Solutions Limitations

#### Single LLM Approach (e.g., ChatGPT)
```
âŒ Problem 1: Shallow Research
   Single LLM call â†’ limited context â†’ superficial content

âŒ Problem 2: No Verification
   Hallucinations â†’ inaccurate information â†’ unreliable

âŒ Problem 3: No Specialization
   One generalist â†’ mediocre at everything

âŒ Problem 4: No Collaboration
   Single perspective â†’ lacks depth
```

### Our Solution

**Multi-Agent Collaboration:**
```
âœ… Multiple specialized agents (better at specific tasks)
âœ… Parallel execution (faster)
âœ… Self-verification (more reliable)
âœ… Iterative improvement (higher quality)
âœ… Transparent reasoning (explainable)
```

---

## ğŸ—ï¸ Solution Architecture

### High-Level System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                               â”‚
â”‚                    (Streamlit Web Application)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTP/REST
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API LAYER (FastAPI)                           â”‚
â”‚  /research  /status/{id}  /health  /feedback                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚                        â”‚
        â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  META AGENT      â”‚  â”‚  WORKER          â”‚  â”‚  STORAGE         â”‚
â”‚  ORCHESTRATION   â”‚  â”‚  EXECUTION       â”‚  â”‚  LAYER           â”‚
â”‚                  â”‚  â”‚                  â”‚  â”‚                  â”‚
â”‚  â€¢ Controller    â”‚  â”‚  â€¢ 17 Specializedâ”‚  â”‚  â€¢ PostgreSQL    â”‚
â”‚  â€¢ Planner       â”‚  â”‚    Workers       â”‚  â”‚  â€¢ Redis Cache   â”‚
â”‚  â€¢ Strategy      â”‚  â”‚  â€¢ BaseWorker    â”‚  â”‚  â€¢ Vector DB     â”‚
â”‚  â€¢ Orchestrator  â”‚  â”‚  â€¢ WorkerFactory â”‚  â”‚    (Future)      â”‚
â”‚  â€¢ Supervisor    â”‚  â”‚                  â”‚  â”‚                  â”‚
â”‚  â€¢ Merger        â”‚  â”‚                  â”‚  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXTERNAL TOOLS & APIs                             â”‚
â”‚  â€¢ Tavily (Web Search)    â€¢ ArXiv (Academic)    â€¢ Claude (LLM)      â”‚
â”‚  â€¢ NewsAPI (News)         â€¢ Firecrawl (Scraping) â€¢ LanguageTool     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Three-Layer Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: DATA SCHEMAS (Pydantic Models)               â”‚
â”‚  Define: Brief, Plan, Task, State, Worker I/O, Result  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2: BUSINESS LOGIC (Agent Classes)               â”‚
â”‚  Implement: Planning, Strategy, Execution, Evaluation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 3: LLM PROMPTS (Prompt Templates)               â”‚
â”‚  Guide: Research, Analysis, Writing, Quality Checking  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technical Stack

### Core Technologies

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Language** | Python | 3.12+ | Main development language |
| **LLM** | Claude 3.5 Sonnet | Latest | Reasoning & generation |
| **Framework** | LangChain + LangGraph | Latest | Agent orchestration |
| **Backend API** | FastAPI | 0.104+ | REST API endpoints |
| **Frontend UI** | Streamlit | 1.28+ | Web interface |
| **Database** | PostgreSQL | 15+ | Persistent storage |
| **Cache** | Redis | 7+ | Query caching |
| **Orchestration** | LangGraph | Latest | State machine workflow |
| **Validation** | Pydantic | 2.5+ | Data validation |
| **Testing** | pytest | Latest | Unit & integration tests |
| **Containerization** | Docker | Latest | Deployment |

### External APIs & Tools

| Service | Purpose | Pricing |
|---------|---------|---------|
| **Anthropic Claude** | LLM for reasoning & writing | $3/1M input tokens |
| **Tavily API** | Web search | $1/1K searches |
| **ArXiv API** | Academic papers | Free |
| **NewsAPI** | Recent news | Free tier available |
| **Firecrawl** | Web scraping | $0.001/page |
| **LanguageTool** | Grammar checking | Free/Premium |

### Development Tools

- **Version Control**: Git + GitHub
- **CI/CD**: GitHub Actions
- **Monitoring**: LangSmith (LLM tracing)
- **Code Quality**: Black, Ruff, MyPy
- **Documentation**: Markdown, Docstrings

---

## ğŸ§© System Components

### 1. Meta Agent Layer (7 Agents)

**Purpose**: Orchestrate the entire workflow, from planning to final output.
```
Controller â†’ StateManager â†’ Planner â†’ Strategy â†’ Orchestrator â†’ Supervisor â†’ Merger
```

Each agent has a specific responsibility in the workflow coordination.

---

### 2. Worker Layer (17 Specialized Workers)

**Purpose**: Execute actual work (research, analysis, writing, quality checks).

#### Worker Categories:

**A. Research Workers (5)**
- Web Search Worker
- Academic Search Worker
- News Search Worker
- Social Media Worker
- Video Search Worker

**B. Analysis Workers (3)**
- Content Synthesizer Worker
- Summarization Worker
- Insight Extractor Worker

**C. Writing Workers (4)**
- Introduction Writer Worker
- Article Writer Worker
- Conclusion Writer Worker
- Citation Formatter Worker

**D. Quality Workers (5)**
- Fact Checker Worker
- Editor Worker
- SEO Optimizer Worker
- Readability Checker Worker
- Plagiarism Checker Worker

---

### 3. Storage Layer

**A. PostgreSQL (Persistent Storage)**
- Store completed articles
- User feedback
- Execution history
- Cost tracking

**B. Redis (Caching)**
- Query result caching
- Embedding caching
- Session data
- Rate limiting

**C. Vector Database (Future)**
- Document embeddings
- Semantic search
- Knowledge base

---

## ğŸ“Š Data Models & Schemas

### Schema Overview
```
Brief (Input)
  â†“
Plan (Planning)
  â”œâ”€ PlanStep[]
  â†“
AgentState (Execution)
  â”œâ”€ research_results
  â”œâ”€ analysis_results
  â”œâ”€ writing_results
  â”œâ”€ quality_results
  â†“
FinalOutput (Output)
  â”œâ”€ ArticleResult
  â”œâ”€ QualityScore
  â”œâ”€ ExecutionMetrics
  â””â”€ Source[]
```

---

### 1. Brief Schema (`brief_schema.py`)

**Purpose**: User input specification
```python
class Brief(BaseModel):
    """User input for content generation request."""
    
    # Core fields
    request_id: Optional[str] = None
    topic: str  # Main topic
    content_type: ContentType  # ARTICLE, BLOG_POST, REPORT, etc.
    target_length: Optional[int] = 2000  # Target word count
    
    # Research parameters
    research_depth: ResearchDepth = ResearchDepth.MEDIUM
    enable_academic: bool = True
    enable_news: bool = True
    enable_social: bool = False
    
    # Quality parameters
    enable_fact_check: bool = True
    enable_seo: bool = True
    enable_plagiarism_check: bool = False
    
    # Constraints
    max_cost: Optional[float] = None
    max_time_seconds: Optional[int] = None
    
    # Output preferences
    tone: Optional[Tone] = Tone.PROFESSIONAL
    audience: Optional[str] = None
    keywords: Optional[List[str]] = None
```

**Enums:**
```python
class ContentType(str, Enum):
    ARTICLE = "article"
    BLOG_POST = "blog_post"
    RESEARCH_PAPER = "research_paper"
    REPORT = "report"
    TUTORIAL = "tutorial"

class ResearchDepth(str, Enum):
    SHALLOW = "shallow"  # 5-7 sources
    MEDIUM = "medium"    # 10-15 sources
    DEEP = "deep"        # 20+ sources

class Tone(str, Enum):
    PROFESSIONAL = "professional"
    CASUAL = "casual"
    ACADEMIC = "academic"
    CONVERSATIONAL = "conversational"
```

---

### 2. Plan Schema (`plan_schema.py`)

**Purpose**: Execution plan created by Planner
```python
class PlanStep(BaseModel):
    """Single step in execution plan."""
    
    step_id: str
    phase: str  # "research", "analysis", "writing", "quality"
    description: str
    worker_ids: List[str]  # Workers to execute
    depends_on: Optional[List[str]] = None  # Dependency step_ids
    execution_mode: ExecutionMode  # PARALLEL or SEQUENTIAL
    estimated_cost: float
    estimated_time_seconds: int

class Plan(BaseModel):
    """Complete execution plan."""
    
    plan_id: str
    brief_id: str
    created_at: datetime
    
    steps: List[PlanStep]
    total_steps: int = Field(..., ge=1)  # Must have at least 1 step
    
    estimated_total_cost: float
    estimated_total_time: int = Field(..., ge=1)  # At least 1 second
    
    optimization_notes: Optional[List[str]] = None
```

**Execution Modes:**
```python
class ExecutionMode(str, Enum):
    PARALLEL = "parallel"      # Execute workers simultaneously
    SEQUENTIAL = "sequential"  # Execute workers one by one
```

---

### 3. Task Schema (`task_schema.py`)

**Purpose**: Individual worker task
```python
class Task(BaseModel):
    """Individual task for a worker."""
    
    task_id: str
    step_id: str  # Which PlanStep this belongs to
    plan_id: str  # Which Plan this belongs to
    worker_id: str
    
    input_data: Dict[str, Any]
    output_data: Optional[Dict[str, Any]] = None
    
    status: TaskStatus
    priority: TaskPriority
    
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    duration_seconds: Optional[float] = None
    
    cost: Optional[float] = None
    error: Optional[str] = None

class TaskBatch(BaseModel):
    """Batch of tasks for parallel execution."""
    
    batch_id: str
    tasks: List[Task]
```

**Task States:**
```python
class TaskStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class TaskPriority(str, Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
```

---

### 4. State Schema (`state_schema.py`)

**Purpose**: Track complete workflow state
```python
class AgentState(BaseModel):
    """Complete workflow state."""
    
    # Core
    state_id: str
    brief: Brief
    current_phase: WorkflowPhase
    
    # Planning
    current_plan: Optional[Plan] = None
    previous_plans: List[Plan] = []
    
    # Execution
    iteration: int = 0
    max_iterations: int = 3
    
    # Results by phase
    research_results: Optional[Dict[str, Any]] = None
    analysis_results: Optional[Dict[str, Any]] = None
    writing_results: Optional[Dict[str, Any]] = None
    quality_results: Optional[Dict[str, Any]] = None
    
    # Tasks
    all_tasks: List[Task] = []
    completed_tasks: List[Task] = []
    failed_tasks: List[Task] = []
    
    # Costs
    total_cost: float = 0.0
    cost_by_worker: Dict[str, float] = {}
    
    # Quality
    quality_score: Optional[float] = None
    completeness_score: Optional[float] = None
    
    # Decision
    should_continue: bool = True
    supervisor_feedback: Optional[str] = None
    
    # Tracking
    start_time: datetime
    end_time: Optional[datetime] = None
    total_duration_seconds: Optional[float] = None
    
    # History
    agent_actions: List[Dict[str, Any]] = []
    state_history: List[StateHistory] = []
    errors: List[str] = []
```

**Workflow Phases:**
```python
class WorkflowPhase(str, Enum):
    INITIALIZED = "initialized"
    PLANNING = "planning"
    STRATEGY = "strategy"
    EXECUTING = "executing"
    EVALUATING = "evaluating"
    RE_PLANNING = "re_planning"
    MERGING = "merging"
    COMPLETED = "completed"
    FAILED = "failed"
```

---

### 5. Worker Schema (`worker_schema.py`)

**Purpose**: Worker I/O standardization
```python
class WorkerInput(BaseModel):
    """Standard input for all workers."""
    
    task_id: str
    worker_id: str
    phase: str
    
    # Context from previous phases
    brief: Brief
    research_results: Optional[Dict[str, Any]] = None
    analysis_results: Optional[Dict[str, Any]] = None
    writing_results: Optional[Dict[str, Any]] = None
    
    # Worker-specific parameters
    parameters: Optional[Dict[str, Any]] = None

class WorkerOutput(BaseModel):
    """Standard output from all workers."""
    
    task_id: str
    worker_id: str
    
    status: str  # "success" or "failed"
    result: Dict[str, Any]
    
    cost: float
    duration_seconds: float
    
    metadata: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
```

---

### 6. Result Schema (`result_schema.py`)

**Purpose**: Final output to user
```python
class ArticleResult(BaseModel):
    """Generated article."""
    
    title: str
    content: str  # Full article text
    summary: str  # Brief summary
    
    sections: List[Dict[str, str]]  # [{title, content}]
    word_count: int
    reading_time_minutes: int
    
    keywords: List[str]
    meta_description: str

class QualityScore(BaseModel):
    """Quality assessment."""
    
    overall_score: float  # 0-100
    
    factual_accuracy: float
    completeness: float
    clarity: float
    coherence: float
    grammar: float
    seo_score: float
    
    strengths: List[str]
    suggestions: List[str]

class ExecutionMetrics(BaseModel):
    """Execution statistics."""
    
    total_duration_seconds: float
    phase_durations: Dict[str, float]
    
    total_cost: float
    cost_breakdown: Dict[str, float]
    
    workers_used: List[str]
    total_tasks: int
    successful_tasks: int
    failed_tasks: int
    
    total_tokens: int
    input_tokens: int
    output_tokens: int
    
    iterations: int
    re_planning_count: int

class Source(BaseModel):
    """Source citation."""
    
    source_id: str
    title: str
    url: str
    type: str  # "web", "academic", "news"
    
    relevance_score: float
    credibility_score: float
    citation_count: int

class FinalOutput(BaseModel):
    """Complete output to user."""
    
    request_id: str
    brief_topic: str
    
    article: ArticleResult
    quality: QualityScore
    sources: List[Source]
    source_count: int
    
    metrics: ExecutionMetrics
    
    system_notes: List[str]
    warnings: List[str]
    
    created_at: datetime
```

---

## ğŸ¤– Agent Specifications

### Agent Architecture Pattern
```python
class AgentTemplate:
    """Standard pattern for all meta agents."""
    
    def __init__(self):
        """Initialize agent."""
        self.agent_count = 0
    
    def main_method(self, state: AgentState, *args) -> OutputType:
        """Main agent functionality."""
        # 1. Log action
        state.add_agent_action(
            agent_name="AgentName",
            action="action_type",
            details={...}
        )
        
        # 2. Perform work
        result = self._do_work(state, *args)
        
        # 3. Update state
        state.field = result
        
        # 4. Return result
        return result
    
    def _private_helper(self, *args):
        """Helper methods (private)."""
        pass


# Global instance
agent = AgentTemplate()

# Helper function (outside class)
def helper_function(*args):
    """Convenience function."""
    return agent.main_method(*args)
```

---

### 1. Controller Agent

**File**: `src/meta_agent/controller.py`

**Role**: Main entry point and workflow coordinator

**Responsibilities**:
- Receive and validate brief
- Initialize workflow state
- Coordinate all other agents
- Handle errors and recovery
- Return final output

**Key Methods**:
```python
def execute(brief: Brief) -> FinalOutput:
    """
    Main execution method.
    
    Flow:
    1. Initialize state
    2. Execute workflow (planning â†’ execution â†’ evaluation â†’ merging)
    3. Create final output
    4. Return to user
    """

def _initialize_state(brief: Brief) -> AgentState:
    """Create new AgentState from brief."""

def _execute_workflow(state: AgentState) -> AgentState:
    """
    Execute complete workflow with iterations:
    - PLANNING phase: Create execution plan
    - EXECUTING phase: Run workers
    - EVALUATING phase: Check quality
    - RE_PLANNING phase: If quality low, iterate
    - MERGING phase: Create final output
    """

def _create_final_output(state: AgentState) -> FinalOutput:
    """Generate FinalOutput from completed state."""
```

**Mock Implementation (Sprint 1)**:
```python
def _generate_mock_article(brief: Brief) -> str:
    """Generate template-based mock article for testing."""
    return f"""
# Understanding {brief.topic}

## Introduction
{brief.topic} is an important subject...

## Background
Understanding the context...

## Key Concepts
The main ideas include...

## Conclusion
In summary, {brief.topic} represents...
"""
```

---

### 2. State Manager Agent

**File**: `src/meta_agent/state_manager.py`

**Role**: Manage and track workflow state

**Responsibilities**:
- Initialize new workflow state
- Track phase transitions
- Record agent actions
- Manage iteration count
- Provide state snapshots
- Validate state transitions

**Key Methods**:
```python
def initialize_state(brief: Brief, max_iterations: int = 3) -> AgentState:
    """Create new workflow state."""

def update_phase(state: AgentState, new_phase: WorkflowPhase) -> AgentState:
    """
    Transition to new phase.
    
    Valid transitions:
    INITIALIZED â†’ PLANNING
    PLANNING â†’ STRATEGY
    STRATEGY â†’ EXECUTING
    EXECUTING â†’ EVALUATING
    EVALUATING â†’ RE_PLANNING (if continue)
    EVALUATING â†’ MERGING (if complete)
    MERGING â†’ COMPLETED
    any â†’ FAILED (on error)
    """

def increment_iteration(state: AgentState) -> AgentState:
    """Increment iteration counter."""

def add_cost(state: AgentState, worker_id: str, cost: float) -> None:
    """Track cost by worker."""

def record_plan(state: AgentState, plan: Plan) -> None:
    """Store execution plan."""

def mark_completed(state: AgentState) -> None:
    """Mark workflow as complete."""

def mark_failed(state: AgentState, reason: str) -> None:
    """Mark workflow as failed."""

def get_state_summary(state: AgentState) -> Dict[str, Any]:
    """Generate summary for logging/debugging."""
```

**State History Tracking**:
```python
def _create_snapshot(state: AgentState) -> StateHistory:
    """
    Create state snapshot at key points:
    - Initialization
    - Phase changes
    - Plan recording
    - Completion
    """
```

---

### 3. Planner Agent

**File**: `src/meta_agent/planner.py`

**Role**: Analyze brief and create execution plan

**Responsibilities**:
- Analyze brief complexity
- Select appropriate workers from registry
- Create step-by-step execution plan
- Define dependencies between steps
- Estimate cost and time
- Generate re-plans based on feedback

**Key Methods**:
```python
def create_plan(state: AgentState) -> Plan:
    """
    Create execution plan from brief.
    
    Steps:
    1. Analyze brief (complexity, requirements)
    2. Select workers (based on analysis)
    3. Create steps (group workers by phase)
    4. Estimate costs and times
    5. Return Plan object
    """

def _analyze_brief(brief: Brief) -> Dict[str, Any]:
    """
    Analyze brief to determine requirements.
    
    Returns:
    {
        "complexity": 0.0-1.0,
        "research_depth": int,
        "multi_hop_needed": bool,
        "recommended_workers": List[str]
    }
    """

def _select_workers(brief: Brief, analysis: Dict) -> Dict[str, List[str]]:
    """
    Select workers by phase based on brief requirements.
    
    Returns:
    {
        "research": ["web_search_worker", "academic_search_worker"],
        "analysis": ["content_synthesizer_worker"],
        "writing": ["article_writer_worker"],
        "quality": ["fact_checker_worker", "editor_worker"]
    }
    """

def _create_steps(selected_workers: Dict, brief: Brief) -> List[PlanStep]:
    """Create PlanStep objects with dependencies and estimates."""

def create_replan(state: AgentState, feedback: str) -> Plan:
    """Generate revised plan based on supervisor feedback."""
```

**Worker Selection Logic (Sprint 1 Mock)**:
```python
# Research phase
workers = ["web_search_worker", "academic_search_worker"]
if brief.enable_news:
    workers.append("news_search_worker")
if complexity > 0.6:
    workers.append("social_media_worker")

# Analysis phase
if multi_hop_needed:
    workers = ["content_synthesizer_worker"]
else:
    workers = ["summarization_worker"]

# Writing phase
if target_length > 3000:
    workers = ["introduction_writer", "article_writer", "conclusion_writer"]
else:
    workers = ["article_writer"]

# Quality phase
workers = []
if enable_fact_check:
    workers.append("fact_checker_worker")
workers.append("editor_worker")
if enable_seo:
    workers.append("seo_optimizer_worker")
```

---

### 4. Strategy Agent

**File**: `src/meta_agent/strategy.py`

**Role**: Optimize execution plan for cost and time

**Responsibilities**:
- Analyze plan efficiency
- Optimize parallel vs sequential execution
- Apply budget constraints
- Apply time constraints
- Balance cost vs quality trade-offs
- Provide optimization recommendations

**Key Methods**:
```python
def optimize_plan(state: AgentState, plan: Plan) -> Plan:
    """
    Optimize execution plan.
    
    Optimizations:
    1. Parallelization (convert sequential to parallel where possible)
    2. Cost optimization (remove non-essential workers if over budget)
    3. Time optimization (enable more parallelization if time-critical)
    
    IMPORTANT: Uses deep copy to preserve original plan!
    """

def _optimize_parallelization(plan: Plan) -> Plan:
    """
    Convert sequential to parallel where workers support it.
    
    Rules:
    - Research workers: can run parallel
    - Analysis workers: usually sequential
    - Writing workers: sequential (maintain flow)
    - Quality workers: can run parallel
    """

def _optimize_for_cost(plan: Plan, max_budget: float) -> Plan:
    """
    Remove non-essential workers to meet budget.
    
    Priority (keep first):
    1. Quality workers (fact-checker, editor)
    2. Writing workers (article_writer)
    3. Analysis workers
    4. Research workers (keep minimum 2)
    """

def _optimize_for_time(plan: Plan, max_time: int) -> Plan:
    """Enable more parallel execution to meet deadline."""

def analyze_plan_efficiency(plan: Plan) -> Dict[str, Any]:
    """
    Calculate efficiency metrics.
    
    Returns:
    {
        "parallelization_ratio": float,  # % of steps that are parallel
        "cost_efficiency": float,
        "time_efficiency": float
    }
    """

def recommend_improvements(plan: Plan, state: AgentState) -> List[str]:
    """Suggest further optimizations."""
```

**Critical Implementation Detail**:
```python
# WRONG - modifies original
optimized_plan = plan
optimized_plan.steps = modified_steps

# CORRECT - preserves original
import copy
optimized_plan = copy.deepcopy(plan)
optimized_plan.steps = modified_steps
```

---

### 5. Orchestrator Agent

**File**: `src/meta_agent/orchestrator.py`

**Role**: Execute plan by dispatching tasks to workers

**Responsibilities**:
- Execute plan steps in order
- Dispatch tasks to workers
- Handle parallel vs sequential execution
- Collect and aggregate results
- Handle failures and retries
- Track progress and costs

**Key Methods**:
```python
def execute_plan(state: AgentState, plan: Plan) -> AgentState:
    """
    Execute complete plan.
    
    Flow:
    1. Loop through each step
    2. Check dependencies
    3. Execute step (parallel or sequential)
    4. Update state with results
    5. Handle errors
    """

def _check_dependencies(step: PlanStep, all_steps: List[PlanStep]) -> bool:
    """Verify that dependency steps are completed."""

def _execute_step(state: AgentState, step: PlanStep, plan: Plan) -> Dict[str, Any]:
    """
    Execute single step.
    
    Routes to:
    - _execute_parallel() if PARALLEL mode
    - _execute_sequential() if SEQUENTIAL mode
    """

def _execute_parallel(state: AgentState, step: PlanStep, plan: Plan) -> Dict[str, Any]:
    """
    Execute multiple workers simultaneously.
    
    Sprint 1: Mock (sequential loop)
    Sprint 2: Real (asyncio.gather())
    """

def _execute_sequential(state: AgentState, step: PlanStep, plan: Plan) -> Dict[str, Any]:
    """Execute workers one by one."""

def _execute_worker(
    state: AgentState, 
    worker_id: str, 
    phase: str,
    step_id: str,
    plan_id: str
) -> Dict[str, Any]:
    """
    Execute single worker.
    
    Steps:
    1. Get worker definition from registry
    2. Create mock result (Sprint 1) or call real worker (Sprint 2)
    3. Track cost
    4. Create Task record
    5. Return result
    """

def _aggregate_results(results: List[Dict], phase: str) -> Dict[str, Any]:
    """
    Combine results from multiple workers.
    
    Research: Merge all sources
    Analysis: Combine insights
    Writing: Concatenate sections
    Quality: Average scores
    """

def _update_state_with_results(
    state: AgentState, 
    step: PlanStep, 
    results: Dict
) -> None:
    """Store results in appropriate state fields."""
```

**Mock Result Generation (Sprint 1)**:
```python
def _create_mock_result(state: AgentState, worker_def: WorkerDefinition, phase: str):
    """Generate phase-specific mock results."""
    
    if phase == "research":
        return {
            "sources": [f"Source {i}" for i in range(3)],
            "summary": f"Research summary by {worker_def.id}",
            "confidence": 0.85
        }
    elif phase == "writing":
        return {
            "content": f"Article content by {worker_def.id}...",
            "word_count": 500,
            "sections": [{"title": "Section 1", "content": "..."}]
        }
    # ... etc
```

---

### 6. Supervisor Agent

**File**: `src/meta_agent/supervisor.py`

**Role**: Evaluate quality and decide next action

**Responsibilities**:
- Evaluate execution results
- Calculate quality scores
- Decide whether to continue iterating or complete
- Provide feedback for improvement
- Identify quality issues
- Recommend next steps

**Key Methods**:
```python
def evaluate(state: AgentState) -> Tuple[bool, str]:
    """
    Evaluate results and make decision.
    
    Returns:
        (should_continue, feedback)
        
    Decision Logic:
    1. If iteration >= max_iterations: COMPLETE (forced)
    2. If quality >= 80% AND completeness >= 75%: COMPLETE
    3. Else: CONTINUE (iterate with feedback)
    """

def _calculate_quality_score(state: AgentState) -> float:
    """
    Calculate overall quality (0.0 to 1.0).
    
    Components:
    - Research quality (source count, success rate)
    - Analysis quality (insight count, confidence)
    - Writing quality (word count, structure)
    - Quality check results (fact accuracy, grammar)
    
    Return: Average of all components
    """

def _calculate_completeness_score(state: AgentState) -> float:
    """
    Calculate completeness (0.0 to 1.0).
    
    Required components:
    - research_results (50%)
    - writing_results (50%)
    
    Bonus:
    - analysis_results (+10%)
    - quality_results (+10%)
    
    Return: Capped at 1.0
    """

def _generate_feedback(state: AgentState, quality: float, completeness: float) -> str:
    """
    Generate specific feedback for improvement.
    
    Examples:
    - "Need 3 more sources" (if source_count < 5)
    - "Article too short (500/2000 words)"
    - "Quality 15% below threshold"
    - "Missing writing results"
    """

def get_quality_report(state: AgentState) -> Dict[str, Any]:
    """Generate detailed quality report for debugging."""
```

**Quality Thresholds**:
```python
self.quality_threshold = 0.80        # 80%
self.completeness_threshold = 0.75   # 75%
self.min_sources = 5
```

---

### 7. Merger Agent

**File**: `src/meta_agent/merger.py`

**Role**: Combine results and format final output

**Responsibilities**:
- Collect all execution results
- Synthesize research findings
- Format final article/content
- Add citations and sources
- Calculate quality metrics
- Generate execution statistics
- Create FinalOutput structure

**Key Methods**:
```python
def merge(state: AgentState) -> FinalOutput:
    """
    Create final output from state.
    
    Steps:
    1. Extract article from writing_results
    2. Create quality scores from evaluation
    3. Extract sources from research_results
    4. Calculate execution metrics
    5. Assemble FinalOutput
    """

def _create_article(state: AgentState) -> ArticleResult:
    """
    Format article from writing results.
    
    Includes:
    - Title generation
    - Content formatting
    - Summary creation
    - Section extraction
    - Reading time calculation
    - Keyword extraction
    - Meta description
    """

def _create_quality_score(state: AgentState) -> QualityScore:
    """
    Format quality assessment.
    
    Uses:
    - state.quality_score (overall)
    - state.quality_results (component scores)
    - Identifies strengths
    - Generates suggestions
    """

def _extract_sources(state: AgentState) -> List[Source]:
    """
    Extract and format sources.
    
    From: state.research_results["all_sources"]
    Creates: Source objects with metadata
    """

def _create_execution_metrics(state: AgentState) -> ExecutionMetrics:
    """
    Calculate execution statistics.
    
    Includes:
    - Duration by phase
    - Cost breakdown by worker
    - Task statistics
    - Token usage estimates
    - Iteration count
    """

def _generate_default_content(state: AgentState) -> str:
    """Generate template-based content if none exists."""

def _generate_system_notes(state: AgentState) -> List[str]:
    """Generate system notes (e.g., "Generated in mock mode")."""

def _generate_warnings(state: AgentState) -> List[str]:
    """Generate warnings if issues occurred."""
```

---

## ğŸ‘· Worker Specifications

### Worker Architecture (Sprint 2)
```python
class BaseWorker:
    """Base class for all workers."""
    
    def __init__(self, worker_id: str):
        self.worker_id = worker_id
        self.registry = WorkerRegistry()
        self.llm = get_llm_config()
    
    def execute(self, input_data: WorkerInput) -> WorkerOutput:
        """
        Standard execution method.
        
        Steps:
        1. Validate input
        2. Prepare context
        3. Execute work (call LLM, API, etc.)
        4. Format output
        5. Track metrics
        6. Return WorkerOutput
        """
        pass
    
    def _prepare_prompt(self, input_data: WorkerInput) -> str:
        """Prepare LLM prompt."""
        pass
    
    def _call_tool(self, **kwargs) -> Any:
        """Call external tool/API."""
        pass
```

### Worker Categories

#### A. Research Workers (Sprint 2)

**1. Web Search Worker**
- **Tool**: Tavily API
- **Purpose**: Search web for relevant information
- **Output**: List of sources with summaries
- **Cost**: ~$0.02 per search

**2. Academic Search Worker**
- **Tool**: ArXiv API
- **Purpose**: Find academic papers
- **Output**: Papers with abstracts
- **Cost**: Free

**3. News Search Worker**
- **Tool**: NewsAPI
- **Purpose**: Find recent news articles
- **Output**: Recent articles
- **Cost**: Free tier

**4. Web Scraper Worker**
- **Tool**: Firecrawl
- **Purpose**: Extract content from URLs
- **Output**: Cleaned text content
- **Cost**: ~$0.001 per page

**5. Social Media Worker**
- **Tool**: Twitter/Reddit APIs
- **Purpose**: Find discussions and trends
- **Output**: Posts, comments, sentiment
- **Cost**: Free/Paid depending on API

---

#### B. Analysis Workers (Sprint 2)

**6. Content Synthesizer Worker**
- **Tool**: Claude LLM
- **Purpose**: Synthesize information from multiple sources
- **Prompt**: "Given these sources, identify key themes and insights..."
- **Output**: Structured insights

**7. Summarization Worker**
- **Tool**: Claude LLM
- **Purpose**: Create concise summaries
- **Prompt**: "Summarize the following content in 200 words..."
- **Output**: Summary text

**8. Insight Extractor Worker**
- **Tool**: Claude LLM
- **Purpose**: Extract key insights
- **Prompt**: "Extract 5 key insights from this research..."
- **Output**: List of insights

---

#### C. Writing Workers (Sprint 2)

**9. Introduction Writer Worker**
- **Tool**: Claude LLM
- **Purpose**: Write engaging introduction
- **Prompt**: "Write an introduction about [topic] that..."
- **Output**: Introduction text

**10. Article Writer Worker**
- **Tool**: Claude LLM
- **Purpose**: Write main article content
- **Prompt**: "Write a comprehensive article about [topic]..."
- **Output**: Full article

**11. Conclusion Writer Worker**
- **Tool**: Claude LLM
- **Purpose**: Write conclusion
- **Prompt**: "Write a conclusion that summarizes..."
- **Output**: Conclusion text

**12. Citation Formatter Worker**
- **Tool**: String processing
- **Purpose**: Format citations properly
- **Output**: Formatted citations

---

#### D. Quality Workers (Sprint 2)

**13. Fact Checker Worker**
- **Tool**: Claude LLM + Web Search
- **Purpose**: Verify factual claims
- **Prompt**: "Verify these claims: [claims]. Check against sources..."
- **Output**: Verification results

**14. Editor Worker**
- **Tool**: LanguageTool + Claude LLM
- **Purpose**: Check grammar and style
- **Output**: Corrected text, suggestions

**15. SEO Optimizer Worker**
- **Tool**: Custom algorithms
- **Purpose**: Optimize for search engines
- **Output**: Keyword suggestions, meta tags

**16. Readability Checker Worker**
- **Tool**: Flesch-Kincaid algorithms
- **Purpose**: Ensure readability
- **Output**: Readability score, suggestions

**17. Plagiarism Checker Worker**
- **Tool**: External API (optional)
- **Purpose**: Check for plagiarism
- **Output**: Similarity scores

---

## ğŸ”„ Workflow & State Machine

### Complete Workflow (LangGraph - Sprint 1E)
```
                    START
                      â”‚
                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   CONTROLLER    â”‚
            â”‚  (Initialize)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    PLANNER      â”‚
            â”‚  (Create Plan)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    STRATEGY     â”‚
            â”‚ (Optimize Plan) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  ORCHESTRATOR   â”‚
            â”‚ (Execute Plan)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   SUPERVISOR    â”‚
            â”‚   (Evaluate)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                   â”‚
    Quality Good?       Quality Low?
           â”‚                   â”‚
           â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  MERGER   â”‚      â”‚  RE-PLANNER â”‚
    â”‚  (Final)  â”‚      â”‚  (Iterate)  â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚
          â–¼                   â”‚
        END                   â”‚
                              â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
              Max Iterations?
                      â”‚
                â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                â”‚           â”‚
               Yes         No
                â”‚           â”‚
                â–¼           â””â”€â”€â–º Back to PLANNER
              END
```

### State Transitions
```python
# Valid phase transitions
INITIALIZED â†’ PLANNING
PLANNING â†’ STRATEGY
STRATEGY â†’ EXECUTING
EXECUTING â†’ EVALUATING

# Decision point
EVALUATING â†’ MERGING (if quality good OR max iterations)
EVALUATING â†’ RE_PLANNING (if quality low AND iterations < max)

# Re-planning loop
RE_PLANNING â†’ PLANNING (create new plan)

# Final states
MERGING â†’ COMPLETED
any â†’ FAILED (on error)
```

### LangGraph Implementation (Phase 1E)
```python
from langgraph.graph import StateGraph, END

# Create graph
graph = StateGraph(AgentState)

# Add nodes
graph.add_node("controller", controller_node)
graph.add_node("planner", planner_node)
graph.add_node("strategy", strategy_node)
graph.add_node("orchestrator", orchestrator_node)
graph.add_node("supervisor", supervisor_node)
graph.add_node("merger", merger_node)

# Add edges
graph.add_edge("controller", "planner")
graph.add_edge("planner", "strategy")
graph.add_edge("strategy", "orchestrator")
graph.add_edge("orchestrator", "supervisor")

# Conditional edges (decision points)
graph.add_conditional_edges(
    "supervisor",
    should_continue_or_complete,
    {
        "continue": "planner",    # Re-plan and iterate
        "complete": "merger"      # Done, merge results
    }
)

graph.add_edge("merger", END)

# Set entry point
graph.set_entry_point("controller")

# Compile
workflow = graph.compile()
```

---

## ğŸ”§ Implementation Details

### Project Structure
```
autoresearch-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ meta_agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ controller.py          # Controller agent
â”‚   â”‚   â”œâ”€â”€ state_manager.py       # State manager
â”‚   â”‚   â”œâ”€â”€ planner.py             # Planner agent
â”‚   â”‚   â”œâ”€â”€ strategy.py            # Strategy agent
â”‚   â”‚   â”œâ”€â”€ orchestrator.py        # Orchestrator agent
â”‚   â”‚   â”œâ”€â”€ supervisor.py          # Supervisor agent
â”‚   â”‚   â”œâ”€â”€ merger.py              # Merger agent
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ brief_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ plan_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ task_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ state_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ worker_schema.py
â”‚   â”‚   â”‚   â””â”€â”€ result_schema.py
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_config.py
â”‚   â”‚   â”‚   â””â”€â”€ worker_registry.py
â”‚   â”‚   â””â”€â”€ workers/               # Sprint 2
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ base_worker.py
â”‚   â”‚       â”œâ”€â”€ research/
â”‚   â”‚       â”œâ”€â”€ analysis/
â”‚   â”‚       â”œâ”€â”€ writing/
â”‚   â”‚       â””â”€â”€ quality/
â”‚   â”œâ”€â”€ tools/                     # Sprint 2
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tavily_tool.py
â”‚   â”‚   â”œâ”€â”€ arxiv_tool.py
â”‚   â”‚   â”œâ”€â”€ news_tool.py
â”‚   â”‚   â””â”€â”€ firecrawl_tool.py
â”‚   â”œâ”€â”€ api/                       # Sprint 3
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â””â”€â”€ ui/                        # Sprint 4
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ app.py
â”‚       â””â”€â”€ components/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_controller.py
â”‚   â”œâ”€â”€ test_state_manager.py
â”‚   â”œâ”€â”€ test_planner.py
â”‚   â”œâ”€â”€ test_strategy.py
â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â”œâ”€â”€ test_supervisor.py
â”‚   â””â”€â”€ test_merger.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SPRINT_PLAN.md
â”‚   â”œâ”€â”€ SESSION_SUMMARY.md
â”‚   â”œâ”€â”€ PROJECT_DOCUMENTATION.md
â”‚   â””â”€â”€ architecture_diagrams/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.ui
â”‚   â””â”€â”€ Dockerfile.worker
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

---

### Configuration Files

#### .env.example
```bash
# LLM Configuration
ANTHROPIC_API_KEY=your_api_key_here
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-5-sonnet-20241022
LLM_MOCK_MODE=true  # Set to false for real API calls

# External Tools
TAVILY_API_KEY=your_tavily_key
NEWS_API_KEY=your_news_key
FIRECRAWL_API_KEY=your_firecrawl_key

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/autoresearch
REDIS_URL=redis://localhost:6379/0

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# Monitoring
LANGSMITH_API_KEY=your_langsmith_key
LANGSMITH_PROJECT=autoresearch-ai
LANGSMITH_TRACING=true

# Limits
MAX_COST_PER_REQUEST=5.0
MAX_TIME_SECONDS=300
MAX_ITERATIONS=3
```

#### requirements.txt
```txt
# Core
python>=3.12
pydantic>=2.5.0
pydantic-settings>=2.1.0

# LLM & AI
anthropic>=0.8.0
langchain>=0.1.0
langchain-anthropic>=0.1.0
langgraph>=0.0.20
langsmith>=0.0.70

# External Tools
tavily-python>=0.3.0
arxiv>=2.0.0
beautifulsoup4>=4.12.0
requests>=2.31.0

# API
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
python-multipart>=0.0.6

# UI
streamlit>=1.28.0

# Database
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0
redis>=5.0.0

# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0

# Development
black>=23.11.0
ruff>=0.1.6
mypy>=1.7.0

# Utilities
python-dotenv>=1.0.0
structlog>=23.2.0
tenacity>=8.2.0
```

---

### Docker Configuration

#### docker-compose.yml
```yaml
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: autoresearch
      POSTGRES_USER: autoresearch
      POSTGRES_PASSWORD: autoresearch_pass
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - autoresearch_network

  # Redis Cache
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - autoresearch_network

  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://autoresearch:autoresearch_pass@postgres:5432/autoresearch
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    depends_on:
      - postgres
      - redis
    networks:
      - autoresearch_network
    volumes:
      - ./src:/app/src

  # Streamlit UI
  ui:
    build:
      context: .
      dockerfile: docker/Dockerfile.ui
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
    depends_on:
      - api
    networks:
      - autoresearch_network

volumes:
  postgres_data:

networks:
  autoresearch_network:
    driver: bridge
```

---

## ğŸ§ª Testing Strategy

### Test Structure
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_agents/
â”‚   â”‚   â”œâ”€â”€ test_controller.py (6 tests)
â”‚   â”‚   â”œâ”€â”€ test_state_manager.py (13 tests)
â”‚   â”‚   â”œâ”€â”€ test_planner.py (9 tests)
â”‚   â”‚   â”œâ”€â”€ test_strategy.py (9 tests)
â”‚   â”‚   â”œâ”€â”€ test_orchestrator.py (9 tests)
â”‚   â”‚   â”œâ”€â”€ test_supervisor.py (9 tests)
â”‚   â”‚   â””â”€â”€ test_merger.py (10 tests)
â”‚   â”œâ”€â”€ test_schemas/
â”‚   â”‚   â”œâ”€â”€ test_brief_schema.py
â”‚   â”‚   â”œâ”€â”€ test_plan_schema.py
â”‚   â”‚   â”œâ”€â”€ test_state_schema.py
â”‚   â”‚   â””â”€â”€ test_result_schema.py
â”‚   â””â”€â”€ test_workers/  # Sprint 2
â”‚       â”œâ”€â”€ test_web_search_worker.py
â”‚       â””â”€â”€ ...
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_workflow.py
â”‚   â”œâ”€â”€ test_agent_communication.py
â”‚   â””â”€â”€ test_end_to_end.py
â””â”€â”€ e2e/
    â””â”€â”€ test_complete_flow.py
```

### Test Patterns
```python
# Standard test pattern
def test_agent_functionality():
    """Test description."""
    # 1. Setup
    agent = AgentClass()
    state = create_mock_state()
    
    # 2. Execute
    result = agent.method(state)
    
    # 3. Assert
    assert result is not None
    assert result.field == expected_value
    
    # 4. Verify state changes
    assert state.updated_field == new_value
    
    print("âœ… Test passed")
```

### Test Coverage Target

- **Unit Tests**: >90% coverage
- **Integration Tests**: All agent interactions
- **E2E Tests**: Complete workflows
- **Performance Tests**: Latency benchmarks

### Running Tests
```bash
# All tests
pytest

# Specific test file
pytest tests/test_controller.py

# With coverage
pytest --cov=src --cov-report=html

# Verbose output
pytest -v

# Stop on first failure
pytest -x
```

---

## ğŸš€ Deployment Architecture

### Development Environment
```
Local Machine
â”œâ”€â”€ Python 3.12 (conda environment)
â”œâ”€â”€ PostgreSQL (Docker)
â”œâ”€â”€ Redis (Docker)
â”œâ”€â”€ Code Editor (VS Code)
â””â”€â”€ Git
```

### Production Environment (Sprint 4)
```
Cloud Platform (Railway/Render)
â”œâ”€â”€ API Service (FastAPI)
â”‚   â”œâ”€â”€ 2 CPU cores
â”‚   â”œâ”€â”€ 4 GB RAM
â”‚   â””â”€â”€ Horizontal scaling
â”œâ”€â”€ UI Service (Streamlit)
â”‚   â”œâ”€â”€ 1 CPU core
â”‚   â””â”€â”€ 2 GB RAM
â”œâ”€â”€ Database (PostgreSQL)
â”‚   â”œâ”€â”€ Managed service
â”‚   â””â”€â”€ Auto-backups
â”œâ”€â”€ Cache (Redis)
â”‚   â”œâ”€â”€ Managed service
â”‚   â””â”€â”€ Persistence enabled
â””â”€â”€ Monitoring (LangSmith)
    â””â”€â”€ LLM tracing & metrics
```

### CI/CD Pipeline
```yaml
# .github/workflows/test.yml
name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      - run: pip install -r requirements.txt
      - run: pytest --cov=src
      - uses: codecov/codecov-action@v3
```

---

## ğŸ“Š Development Progress

### Sprint 1: Foundation (Week 1-2) - 50% Complete

#### Completed âœ…
- **Phase 1A**: Project Setup (4 hours)
  - Folder structure
  - Environment setup
  - Docker configuration
  - Git & CI/CD

- **Phase 1B**: Configuration & Schemas (5 hours)
  - Settings configuration
  - LLM configuration
  - Worker registry (17 workers)
  - 6 Pydantic schemas

- **Phase 1C**: Core Meta Agents (5 hours)
  - Controller Agent
  - State Manager Agent
  - Planner Agent
  - Strategy Agent
  - Orchestrator Agent
  - Supervisor Agent
  - Merger Agent
  - All with comprehensive tests (46 tests, 100% passing)

#### In Progress â³
- **Phase 1D**: Integration & Basic Testing (3 hours)
  - Basic integration test
  - Agent communication test
  - Mock data validation

#### To Do ğŸ“‹
- **Phase 1E**: LangGraph Workflow (9 hours)
  - Create Graph Nodes
  - Create Graph Edges & Conditions
  - Assemble Complete Workflow

- **Phase 1F**: Utilities & Testing (10 hours)
  - Utility Functions
  - Mock Workers (17 workers)
  - LangSmith Tracing
  - Integration Tests
  - CLI Demo

- **Phase 1G**: Documentation & Demo (5 hours)
  - Architecture Documentation
  - API Documentation
  - Demo & Tutorial
  - Sprint 1 Summary

**Total Sprint 1**: 29 tasks, ~52 hours (26 hours done, 26 remaining)

---

### Future Sprints

#### Sprint 2: Workers & Tools (Week 3-4)
- Implement all 17 workers
- Integrate external tools/APIs
- Replace mock implementations
- **Status**: Not started
- **Estimated**: 28 tasks, ~78 hours

#### Sprint 3: API & Storage (Week 5-6)
- FastAPI backend
- PostgreSQL integration
- Redis caching
- Async processing
- **Status**: Not started
- **Estimated**: 21 tasks, ~51 hours

#### Sprint 4: UI & Polish (Week 7-8)
- Streamlit UI
- Comprehensive testing
- Documentation
- Deployment
- **Status**: Not started
- **Estimated**: 28 tasks, ~79 hours

---

## ğŸ“ˆ Key Metrics & Targets

### Performance Targets

| Metric | Target | Current |
|--------|--------|---------|
| Response Time (p95) | <3 seconds | TBD |
| Quality Score | >88/100 | Mock: 88/100 |
| Cost per Article | <$3 | Mock: $0 |
| Source Count | 10-15 | Mock: 5-10 |
| Word Count | 2000+ | Mock: 2000+ |
| Success Rate | >95% | 100% (mock) |

### System Targets

| Metric | Target | Current |
|--------|--------|---------|
| Test Coverage | >90% | ~85% |
| API Uptime | >99% | TBD |
| Error Rate | <1% | 0% (mock) |
| Cache Hit Rate | >30% | TBD |

---

## ğŸ“ Key Learnings & Best Practices

### Technical Learnings

1. **Mock-First Development**
   - Build with mocks, replace incrementally
   - Enables rapid architecture validation
   - Zero cost during development

2. **Type Safety with Pydantic**
   - Catches bugs at validation time
   - Clear data contracts
   - Auto-generated documentation

3. **Three-Layer Architecture**
   - Schemas (data)
   - Logic (agents)
   - Prompts (LLM instructions)
   - Clean separation of concerns

4. **State Management**
   - Single state object flows through system
   - Immutable phase transitions
   - Snapshot-based history

5. **Helper Function Pattern**
```python
   # Inside class (instance method)
   def method(self, arg):
       pass
   
   # Outside class (helper function)
   agent = AgentClass()
   def helper(arg):
       return agent.method(arg)
```

### Common Pitfalls & Solutions

1. **Float Comparison**
   - âŒ `assert cost == 0.15`
   - âœ… `assert abs(cost - 0.15) < 0.01`

2. **Schema Field Names**
   - âŒ `worker_def.worker_id`
   - âœ… `worker_def.id`

3. **Enum Values**
   - âŒ `TaskPriority.NORMAL`
   - âœ… `TaskPriority.MEDIUM`

4. **Deep Copy**
   - âŒ `optimized = plan` (reference)
   - âœ… `optimized = copy.deepcopy(plan)` (independent)

5. **Validation Constraints**
   - `Plan.total_steps >= 1`
   - `Plan.estimated_total_time >= 1`
   - `Brief.max_time_seconds >= 60`

---

## ğŸ”— Resources & References

### Documentation
- [Sprint Plan](./SPRINT_PLAN.md) - Detailed sprint breakdown
- [Session Summary](./SESSION_SUMMARY.md) - Quick context for new chats
- [Architecture Diagrams](./architecture_diagrams/) - Visual diagrams

### External APIs
- [Anthropic Claude API](https://docs.anthropic.com/)
- [Tavily Search API](https://docs.tavily.com/)
- [ArXiv API](https://info.arxiv.org/help/api/)
- [NewsAPI](https://newsapi.org/docs)

### Frameworks
- [LangChain](https://python.langchain.com/)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://docs.streamlit.io/)
- [Pydantic](https://docs.pydantic.dev/)

### Tools
- [LangSmith](https://docs.smith.langchain.com/) - LLM tracing
- [Docker](https://docs.docker.com/)
- [PostgreSQL](https://www.postgresql.org/docs/)
- [Redis](https://redis.io/docs/)

---

## ğŸ¯ Next Steps

### Immediate (This Week)
1. Complete Phase 1D: Integration testing
2. Start Phase 1E: LangGraph workflow
3. Document architecture decisions

### Short Term (Next 2 Weeks)
1. Complete Sprint 1 (Phases 1E, 1F, 1G)
2. Sprint 1 review and retrospective
3. Begin Sprint 2: Worker implementation

### Long Term (Weeks 3-8)
1. Complete all 17 workers (Sprint 2)
2. Build FastAPI backend (Sprint 3)
3. Create Streamlit UI (Sprint 4)
4. Deploy to production

---

## ğŸ‘¥ Project Information

**Developer**: Jihaad  
**Project**: AutoResearch AI  
**Duration**: 8 weeks (part-time)  
**Current Sprint**: Sprint 1 (50% complete)  
**Status**: On track âœ…

---

## ğŸ“ Document Metadata

**File**: docs/PROJECT_DOCUMENTATION.md  
**Version**: 1.0  
**Last Updated**: November 25, 2024  
**Document Type**: Living Document (Updated Weekly)  
**Completeness**: Comprehensive

---

**END OF DOCUMENTATION**